{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Prelude"
      ],
      "metadata": {
        "id": "dWkJiY0Ss_Lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets==2.14.4 'transformers[torch]' evaluate gcsfs scikit-learn torchinfo torch torchaudio datasets"
      ],
      "metadata": {
        "id": "dfT9vv8zJvr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6JmX-UuWK9J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import librosa\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torchaudio\n",
        "import evaluate\n",
        "from accelerate import notebook_launcher\n",
        "from datasets import Audio, load_from_disk, load_dataset\n",
        "from transformers import AutoFeatureExtractor\n",
        "from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n",
        "from typing import List, Dict, Tuple\n",
        "from torch.utils.data import DataLoader\n",
        "from torchinfo import summary\n",
        "from huggingface_hub import login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrZd3zjc7Dg_"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    dev = \"cuda:0\"\n",
        "    print(\"Using GPU\")\n",
        "else:\n",
        "    print(\"No GPU\")\n",
        "    dev = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-O_QNMxCcGY",
        "outputId": "c0dfea5c-c1a4-4dea-fe7a-74eef96b2ae3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "my_token = \"REDACTED\"\n",
        "\n",
        "assert my_token != \"REDACTED\", \"Please provide a huggingface token.\"\n",
        "login(token=my_token)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing"
      ],
      "metadata": {
        "id": "6WSl0UPTs-PS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine classes\n",
        "accents = ['United States English',\n",
        "            'England English',\n",
        "            'India and South Asia (India, Pakistan, Sri Lanka)']\n",
        "accents_map = {accent: i for i, accent in enumerate(accents)}\n",
        "SAMPLING_RATE = 16_000\n",
        "SECONDS = 3\n",
        "\n",
        "\n",
        "def process_dataset(dataset, filter: bool = True):\n",
        "    def trim_audio(example):\n",
        "        example['audio']['array'], index = librosa.effects.trim(y=example['audio']['array'])\n",
        "        return example\n",
        "\n",
        "    def crop_audio(example):\n",
        "        example[\"audio\"][\"array\"] = example[\"audio\"][\"array\"][:SECONDS * SAMPLING_RATE]\n",
        "        return example\n",
        "\n",
        "    def balance_data(example):\n",
        "        return example[\"accent\"] != \"United States English\" or random.randint(0, 2) == 0\n",
        "\n",
        "    def encode_accent(example):\n",
        "        return {\"accent\": accents_map[example[\"accent\"]]}\n",
        "\n",
        "    # Remove columns other than audio and accent\n",
        "    dataset = dataset.select_columns([\"audio\", \"accent\"])\n",
        "    # Fix sampling rate\n",
        "    dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=SAMPLING_RATE))\n",
        "\n",
        "    # Remove unwanted accents\n",
        "    dataset = dataset.filter(lambda x: x in accents, num_proc=8)\n",
        "\n",
        "    if filter:\n",
        "      # Remove a third of US accent samples to balance the data\n",
        "      random.seed(a=1)\n",
        "      dataset = dataset.filter(balance_data)\n",
        "\n",
        "    # Trim silence at beginning and end of clip\n",
        "    dataset = dataset.map(trim_audio, num_proc=8)\n",
        "\n",
        "    # Filter out short clips\n",
        "    dataset = dataset.filter(lambda example: example[\"audio\"][\"array\"].shape[0] >= SECONDS * SAMPLING_RATE, num_proc=8)\n",
        "\n",
        "    # Trim anything past SECONDS\n",
        "    dataset = dataset.map(crop_audio, num_proc=8)\n",
        "\n",
        "    # Encode accent\n",
        "    dataset = dataset.map(encode_accent, num_proc=8)\n",
        "\n",
        "    # wav2vec2 model requires output column to be named \"label\"\n",
        "    dataset = dataset.rename_column(\"accent\", \"label\")\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "YQ9xCwqOMToS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Extraction\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n",
        "assert feature_extractor.sampling_rate == SAMPLING_RATE\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
        "    inputs = feature_extractor(\n",
        "        audio_arrays, sampling_rate=SAMPLING_RATE, max_length=SECONDS*SAMPLING_RATE, truncation=True\n",
        "    )\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "XWCdF2kHPYvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Common Voice dataset from Hugging Face\n",
        "dataset = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"en\", split=\"train\", cache_dir=\"cache\")\n",
        "\n",
        "dataset = process_dataset(dataset)\n",
        "\n",
        "dataset = dataset.map(\n",
        "    preprocess_function,\n",
        "    remove_columns=\"audio\",\n",
        "    batched=True,\n",
        "    batch_size=2000,\n",
        "    load_from_cache_file=False,\n",
        "    num_proc=8,\n",
        ")\n",
        "train = dataset"
      ],
      "metadata": {
        "id": "05XK_JplPSCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Validation set\n",
        "val = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"en\", split=\"validation\", cache_dir=\"cache\")\n",
        "\n",
        "val = process_dataset(val, filter=False)\n",
        "\n",
        "val = val.map(\n",
        "    preprocess_function,\n",
        "    remove_columns=\"audio\",\n",
        "    batched=True,\n",
        "    batch_size=2000,\n",
        "    load_from_cache_file=False,\n",
        "    num_proc=8,\n",
        ")"
      ],
      "metadata": {
        "id": "3mK63OYjQTjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test set\n",
        "test = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"en\", split=\"test\", cache_dir=\"cache\")\n",
        "\n",
        "test = process_dataset(test, filter=False)\n",
        "\n",
        "test = test.map(\n",
        "    preprocess_function,\n",
        "    remove_columns=\"audio\",\n",
        "    batched=True,\n",
        "    batch_size=2000,\n",
        "    load_from_cache_file=False,\n",
        "    num_proc=8,\n",
        ")"
      ],
      "metadata": {
        "id": "rC3tue06J1jl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and feature extraction"
      ],
      "metadata": {
        "id": "C5foJlKf4rx1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-MdrM99CcGa"
      },
      "outputs": [],
      "source": [
        "label2id = accents_map\n",
        "id2label = {v: k for k, v in label2id.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "49e9f4310d734e87977dd306ee402d28",
            "e333a340052842a3bead93a55be7ef86",
            "469f40035c2f4483959173b5ea70ff35",
            "40a6d3c25c904d6e856c5dfe7001675f",
            "38b4500df6ae4c669bfdb28463aea391",
            "a8d70dccb44b43598a2b39597ee7d759",
            "87538fc591e449f9be8786354e27eff3",
            "15c848d9fb5c45cba35035968295592b",
            "91f3bf93def8471498e254fb5922fe5e",
            "68705234e29a47f9a5e79eb96046552f",
            "ce4d77aa788044b1ba0b9f2ab5fb5af1"
          ],
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "LnnRnflCCcGc",
        "outputId": "74848dab-d897-4da8-d3b8-3c0bc5db5578"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "49e9f4310d734e87977dd306ee402d28"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "accuracy = evaluate.load(\"accuracy\")\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)\n",
        "\n",
        "\n",
        "def train_model(model, batch_size, lr):\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"model_out_6\",\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        learning_rate=lr,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        gradient_accumulation_steps=4,\n",
        "        per_device_eval_batch_size=32,\n",
        "        # Only the first 4 epochs were analysed in the dissertation\n",
        "        num_train_epochs=5,\n",
        "        warmup_ratio=0.1,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        # Upload to model to hub after each training epoch\n",
        "        push_to_hub=True,\n",
        "        # Load data in separate thread\n",
        "        dataloader_num_workers=1,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train.with_format(\"torch\"),\n",
        "        eval_dataset=val.with_format(\"torch\"),\n",
        "        tokenizer=feature_extractor,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "    trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experiment: Batch size and learning rate"
      ],
      "metadata": {
        "id": "F_Hm_FS4DKQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each train batch size and learning rate combination was set to train for 5 epochs as can be seen in the code of the previous cell. However, during the training of model5 (batch size 8, learning rate 1e-6) there was a connectivity error that caused training to stop before the 5th epoch. Instead of retraining the model from scratch (since training time per 5 epochs was roughly 6 hours), I decided to only compare the first 4 epochs for each model."
      ],
      "metadata": {
        "id": "XA5qiJ-mIc3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Batch Size 8, learning rate 1e-6"
      ],
      "metadata": {
        "id": "vrv-f1B7Dy4P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "785da07e-2bd3-40f3-8a99-228d7020db85",
        "id": "ol_tOYKlEjZ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "25bb2059277a48feb1500c43b922b1ed",
            "7d5cb036ba53492bbf1eb5d4e8ddee68",
            "e4301bfaee904e9aa1d70f02e728f0ea",
            "91ef35ca6fad48768f3fb03de89c6389",
            "74ca9634f7ae4d83a631cbb0a556b043",
            "15439c44f14b46968ade8a3c39b8e17a",
            "c92cfe4bde354629b2b95298ed5ae4ef",
            "fb378b5048ee43beaac61cd78c6511a7",
            "3b927c7d91eb4e519b4b529664fb61d4",
            "2d7fafac09224ffab2f5afb6a427bddf",
            "f44ad89c4570409ba5c8f407ca74b039"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/380M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25bb2059277a48feb1500c43b922b1ed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'projector.weight', 'projector.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model1 = AutoModelForAudioClassification.from_pretrained(\n",
        "    \"facebook/wav2vec2-base\", num_labels=len(accents), label2id=label2id, id2label=id2label\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mG8QVaI8CcGh",
        "outputId": "deb28662-7c0f-486d-9a1e-41b2e21dab9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching training on one GPU.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36670' max='36670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [36670/36670 6:04:38, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.193400</td>\n",
              "      <td>0.590846</td>\n",
              "      <td>0.781775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.178000</td>\n",
              "      <td>0.605535</td>\n",
              "      <td>0.775779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.240700</td>\n",
              "      <td>0.634270</td>\n",
              "      <td>0.780576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.225900</td>\n",
              "      <td>0.625045</td>\n",
              "      <td>0.780576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.134600</td>\n",
              "      <td>0.644285</td>\n",
              "      <td>0.776978</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Use accelerate library to setup GPU and run training.\n",
        "notebook_launcher(train_model(model=model1, batch_size=8, lr=1e-6), num_processes=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Batch Size 8, learning rate 1e-5"
      ],
      "metadata": {
        "id": "yY0mWdNdDy_w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcE2b6BJCcGf",
        "outputId": "96a3d31c-7238-43da-8b01-67df918d0e7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.weight', 'classifier.bias', 'projector.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model2 = AutoModelForAudioClassification.from_pretrained(\n",
        "    \"facebook/wav2vec2-base\", num_labels=len(accents), label2id=label2id, id2label=id2label\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "83b3012c-b5bb-4c84-d645-9360ee3daea1",
        "id": "jnvZBk7CEtab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching training on one GPU.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36670' max='36670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [36670/36670 6:05:22, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.129900</td>\n",
              "      <td>0.666345</td>\n",
              "      <td>0.784173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.122600</td>\n",
              "      <td>0.754313</td>\n",
              "      <td>0.784173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.133900</td>\n",
              "      <td>0.881027</td>\n",
              "      <td>0.791367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.073000</td>\n",
              "      <td>1.001559</td>\n",
              "      <td>0.794964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.057300</td>\n",
              "      <td>1.165421</td>\n",
              "      <td>0.778177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "notebook_launcher(train_model(model=model2, batch_size=8, lr=1e-5), num_processes=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Batch Size 8, learning rate 1e-4"
      ],
      "metadata": {
        "id": "nlw_dzJzDzJz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "96a3d31c-7238-43da-8b01-67df918d0e7b",
        "id": "1fQF_-cwEj58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.weight', 'classifier.bias', 'projector.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model3 = AutoModelForAudioClassification.from_pretrained(\n",
        "    \"facebook/wav2vec2-base\", num_labels=len(accents), label2id=label2id, id2label=id2label\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "catboEsaCcGf",
        "outputId": "02eebf8a-bce6-48ed-805c-d6c739ba4d29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching training on one GPU.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='36670' max='36670' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [36670/36670 6:05:05, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.295800</td>\n",
              "      <td>0.828595</td>\n",
              "      <td>0.718225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.218500</td>\n",
              "      <td>0.662201</td>\n",
              "      <td>0.766187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.242400</td>\n",
              "      <td>0.698771</td>\n",
              "      <td>0.769784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.175900</td>\n",
              "      <td>0.797571</td>\n",
              "      <td>0.793765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.124200</td>\n",
              "      <td>0.872529</td>\n",
              "      <td>0.796163</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "notebook_launcher(train_model(model=model3, batch_size=8, lr=1e-4), num_processes=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Batch Size 16, learning rate 1e-6"
      ],
      "metadata": {
        "id": "D3_VgvwoDw0S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "96a3d31c-7238-43da-8b01-67df918d0e7b",
        "id": "Q8d0-R4FEkT5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.weight', 'classifier.bias', 'projector.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model4 = AutoModelForAudioClassification.from_pretrained(\n",
        "    \"facebook/wav2vec2-base\", num_labels=len(accents), label2id=label2id, id2label=id2label\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElYP036mCpwV",
        "outputId": "55437cfd-5e75-4f74-c6f6-0708c659fb1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching training on one GPU.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18335' max='18335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18335/18335 5:30:03, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.215600</td>\n",
              "      <td>0.590660</td>\n",
              "      <td>0.779376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.225300</td>\n",
              "      <td>0.570457</td>\n",
              "      <td>0.780576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.249600</td>\n",
              "      <td>0.613570</td>\n",
              "      <td>0.773381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.123700</td>\n",
              "      <td>0.610534</td>\n",
              "      <td>0.776978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.195800</td>\n",
              "      <td>0.601529</td>\n",
              "      <td>0.779376</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "notebook_launcher(train_model, num_processes=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Batch Size 16, learning rate 1e-5"
      ],
      "metadata": {
        "id": "FRFeWrjTDxAy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "96a3d31c-7238-43da-8b01-67df918d0e7b",
        "id": "rLeHkIW3EkoQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.weight', 'classifier.bias', 'projector.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model5 = AutoModelForAudioClassification.from_pretrained(\n",
        "    \"facebook/wav2vec2-base\", num_labels=len(accents), label2id=label2id, id2label=id2label\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4M9307M6GNj",
        "outputId": "f3795d21-2f92-48f6-bdd3-f9a44c29c7a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching training on one GPU.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='17217' max='18335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [17217/18335 5:42:23 < 22:14, 0.84 it/s, Epoch 4.69/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.142900</td>\n",
              "      <td>0.637826</td>\n",
              "      <td>0.790168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.101100</td>\n",
              "      <td>0.750809</td>\n",
              "      <td>0.772182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.092600</td>\n",
              "      <td>0.792801</td>\n",
              "      <td>0.770983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.053100</td>\n",
              "      <td>0.868151</td>\n",
              "      <td>0.790168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "notebook_launcher(train_model(model=model5, batch_size=16, lr=1e-5), num_processes=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Batch Size 16, learning rate 1e-4"
      ],
      "metadata": {
        "id": "QRD_t1gfDRrH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "outputId": "96a3d31c-7238-43da-8b01-67df918d0e7b",
        "id": "BCGJyHi7Egv3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/.local/lib/python3.10/site-packages/transformers/configuration_utils.py:380: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['projector.weight', 'classifier.bias', 'projector.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model6 = AutoModelForAudioClassification.from_pretrained(\n",
        "    \"facebook/wav2vec2-base\", num_labels=len(accents), label2id=label2id, id2label=id2label\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZyNDzdGCcGf",
        "outputId": "20136087-3114-4f2d-eb67-5b3d98d73582"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Launching training on one GPU.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='18335' max='18335' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [18335/18335 5:31:27, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.161000</td>\n",
              "      <td>0.666441</td>\n",
              "      <td>0.766187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.193200</td>\n",
              "      <td>0.645268</td>\n",
              "      <td>0.793765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.165400</td>\n",
              "      <td>0.730128</td>\n",
              "      <td>0.808153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.081000</td>\n",
              "      <td>0.873766</td>\n",
              "      <td>0.792566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.036000</td>\n",
              "      <td>1.055973</td>\n",
              "      <td>0.787770</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "notebook_launcher(train_model(model=model6, batch_size=16, lr=1e-4), num_processes=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Visualisations"
      ],
      "metadata": {
        "id": "2kFv4100Lq5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualisations were created in a seperate file attached."
      ],
      "metadata": {
        "id": "N9gLI3W8tHtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "RXOsu-waDtZw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBu8CS6BCcGi",
        "outputId": "3bd8fa2e-7773-4431-852a-55e13ec073cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'accuracy': 0.23621103117505995}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initial validation accuracy before fine-tuning\n",
        "model_tmp = AutoModelForAudioClassification.from_pretrained(\n",
        "    \"facebook/wav2vec2-base\", num_labels=len(accents), label2id=label2id, id2label=id2label\n",
        ").to(dev)\n",
        "predictions = []\n",
        "for batch in DataLoader(val.with_format(\"torch\", device=dev), batch_size=32):\n",
        "    outputs = model_tmp(batch[\"input_values\"]).logits\n",
        "    predictions.append(torch.argmax(outputs, dim=1))\n",
        "\n",
        "accuracy.compute(predictions=torch.cat(predictions), references=val[\"label\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYE871BQCcGd",
        "outputId": "7baa5130-d83b-4303-f947-8ce64c0d97ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.7559, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Test set evaluation on best model after training\n",
        "total_correct = 0\n",
        "total = 1113 # len(test)\n",
        "\n",
        "# Move to GPU\n",
        "test = test.with_format(\"torch\", device=dev)\n",
        "\n",
        "for batch in DataLoader(test, batch_size=32):\n",
        "    outputs = model6(batch[\"input_values\"], labels=batch[\"label\"])\n",
        "    correct = torch.sum(torch.argmax(outputs.logits, dim=1) == batch[\"label\"])\n",
        "    total_correct += correct\n",
        "\n",
        "print(total_correct / total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr9TI0oGCcGi",
        "outputId": "053549b0-b97d-496c-8b53-a370d6a815bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "=========================================================================================================\n",
              "Layer (type:depth-idx)                                  Output Shape              Param #\n",
              "=========================================================================================================\n",
              "Wav2Vec2ForSequenceClassification                       [16, 3]                   --\n",
              "├─Wav2Vec2Model: 1-1                                    [16, 149, 512]            768\n",
              "│    └─Wav2Vec2FeatureEncoder: 2-1                      [16, 512, 149]            --\n",
              "│    │    └─ModuleList: 3-1                             --                        --\n",
              "│    │    │    └─Wav2Vec2GroupNormConvLayer: 4-1        [16, 512, 9599]           --\n",
              "│    │    │    │    └─Conv1d: 5-1                       [16, 512, 9599]           5,120\n",
              "│    │    │    │    └─GroupNorm: 5-2                    [16, 512, 9599]           1,024\n",
              "│    │    │    │    └─GELUActivation: 5-3               [16, 512, 9599]           --\n",
              "│    │    │    └─Wav2Vec2NoLayerNormConvLayer: 4-2      [16, 512, 4799]           --\n",
              "│    │    │    │    └─Conv1d: 5-4                       [16, 512, 4799]           786,432\n",
              "│    │    │    │    └─GELUActivation: 5-5               [16, 512, 4799]           --\n",
              "│    │    │    └─Wav2Vec2NoLayerNormConvLayer: 4-3      [16, 512, 2399]           --\n",
              "│    │    │    │    └─Conv1d: 5-6                       [16, 512, 2399]           786,432\n",
              "│    │    │    │    └─GELUActivation: 5-7               [16, 512, 2399]           --\n",
              "│    │    │    └─Wav2Vec2NoLayerNormConvLayer: 4-4      [16, 512, 1199]           --\n",
              "│    │    │    │    └─Conv1d: 5-8                       [16, 512, 1199]           786,432\n",
              "│    │    │    │    └─GELUActivation: 5-9               [16, 512, 1199]           --\n",
              "│    │    │    └─Wav2Vec2NoLayerNormConvLayer: 4-5      [16, 512, 599]            --\n",
              "│    │    │    │    └─Conv1d: 5-10                      [16, 512, 599]            786,432\n",
              "│    │    │    │    └─GELUActivation: 5-11              [16, 512, 599]            --\n",
              "│    │    │    └─Wav2Vec2NoLayerNormConvLayer: 4-6      [16, 512, 299]            --\n",
              "│    │    │    │    └─Conv1d: 5-12                      [16, 512, 299]            524,288\n",
              "│    │    │    │    └─GELUActivation: 5-13              [16, 512, 299]            --\n",
              "│    │    │    └─Wav2Vec2NoLayerNormConvLayer: 4-7      [16, 512, 149]            --\n",
              "│    │    │    │    └─Conv1d: 5-14                      [16, 512, 149]            524,288\n",
              "│    │    │    │    └─GELUActivation: 5-15              [16, 512, 149]            --\n",
              "│    └─Wav2Vec2FeatureProjection: 2-2                   [16, 149, 768]            --\n",
              "│    │    └─LayerNorm: 3-2                              [16, 149, 512]            1,024\n",
              "│    │    └─Linear: 3-3                                 [16, 149, 768]            393,984\n",
              "│    │    └─Dropout: 3-4                                [16, 149, 768]            --\n",
              "│    └─Wav2Vec2Encoder: 2-3                             [16, 149, 768]            --\n",
              "│    │    └─Wav2Vec2PositionalConvEmbedding: 3-5        [16, 149, 768]            --\n",
              "│    │    │    └─Conv1d: 4-8                            [16, 768, 150]            4,719,488\n",
              "│    │    │    └─Wav2Vec2SamePadLayer: 4-9              [16, 768, 149]            --\n",
              "│    │    │    └─GELUActivation: 4-10                   [16, 768, 149]            --\n",
              "│    │    └─LayerNorm: 3-6                              [16, 149, 768]            1,536\n",
              "│    │    └─Dropout: 3-7                                [16, 149, 768]            --\n",
              "│    │    └─ModuleList: 3-8                             --                        --\n",
              "│    │    │    └─Wav2Vec2EncoderLayer: 4-11             [16, 149, 768]            --\n",
              "│    │    │    │    └─Wav2Vec2Attention: 5-16           [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-1                  [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-2                  [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-3                  [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-4                  [16, 149, 768]            590,592\n",
              "│    │    │    │    └─Dropout: 5-17                     [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-18                   [16, 149, 768]            1,536\n",
              "│    │    │    │    └─Wav2Vec2FeedForward: 5-19         [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-5                  [16, 149, 3072]           2,362,368\n",
              "│    │    │    │    │    └─GELUActivation: 6-6          [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Dropout: 6-7                 [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Linear: 6-8                  [16, 149, 768]            2,360,064\n",
              "│    │    │    │    │    └─Dropout: 6-9                 [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-20                   [16, 149, 768]            1,536\n",
              "│    │    │    └─Wav2Vec2EncoderLayer: 4-12             [16, 149, 768]            --\n",
              "│    │    │    │    └─Wav2Vec2Attention: 5-21           [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-10                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-11                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-12                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-13                 [16, 149, 768]            590,592\n",
              "│    │    │    │    └─Dropout: 5-22                     [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-23                   [16, 149, 768]            1,536\n",
              "│    │    │    │    └─Wav2Vec2FeedForward: 5-24         [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-14                 [16, 149, 3072]           2,362,368\n",
              "│    │    │    │    │    └─GELUActivation: 6-15         [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Dropout: 6-16                [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Linear: 6-17                 [16, 149, 768]            2,360,064\n",
              "│    │    │    │    │    └─Dropout: 6-18                [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-25                   [16, 149, 768]            1,536\n",
              "│    │    │    └─Wav2Vec2EncoderLayer: 4-13             [16, 149, 768]            --\n",
              "│    │    │    │    └─Wav2Vec2Attention: 5-26           [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-19                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-20                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-21                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-22                 [16, 149, 768]            590,592\n",
              "│    │    │    │    └─Dropout: 5-27                     [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-28                   [16, 149, 768]            1,536\n",
              "│    │    │    │    └─Wav2Vec2FeedForward: 5-29         [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-23                 [16, 149, 3072]           2,362,368\n",
              "│    │    │    │    │    └─GELUActivation: 6-24         [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Dropout: 6-25                [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Linear: 6-26                 [16, 149, 768]            2,360,064\n",
              "│    │    │    │    │    └─Dropout: 6-27                [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-30                   [16, 149, 768]            1,536\n",
              "│    │    │    └─Wav2Vec2EncoderLayer: 4-14             [16, 149, 768]            --\n",
              "│    │    │    │    └─Wav2Vec2Attention: 5-31           [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-28                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-29                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-30                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-31                 [16, 149, 768]            590,592\n",
              "│    │    │    │    └─Dropout: 5-32                     [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-33                   [16, 149, 768]            1,536\n",
              "│    │    │    │    └─Wav2Vec2FeedForward: 5-34         [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-32                 [16, 149, 3072]           2,362,368\n",
              "│    │    │    │    │    └─GELUActivation: 6-33         [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Dropout: 6-34                [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Linear: 6-35                 [16, 149, 768]            2,360,064\n",
              "│    │    │    │    │    └─Dropout: 6-36                [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-35                   [16, 149, 768]            1,536\n",
              "│    │    │    └─Wav2Vec2EncoderLayer: 4-15             [16, 149, 768]            --\n",
              "│    │    │    │    └─Wav2Vec2Attention: 5-36           [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-37                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-38                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-39                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-40                 [16, 149, 768]            590,592\n",
              "│    │    │    │    └─Dropout: 5-37                     [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-38                   [16, 149, 768]            1,536\n",
              "│    │    │    │    └─Wav2Vec2FeedForward: 5-39         [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-41                 [16, 149, 3072]           2,362,368\n",
              "│    │    │    │    │    └─GELUActivation: 6-42         [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Dropout: 6-43                [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Linear: 6-44                 [16, 149, 768]            2,360,064\n",
              "│    │    │    │    │    └─Dropout: 6-45                [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-40                   [16, 149, 768]            1,536\n",
              "│    │    │    └─Wav2Vec2EncoderLayer: 4-16             [16, 149, 768]            --\n",
              "│    │    │    │    └─Wav2Vec2Attention: 5-41           [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-46                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-47                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-48                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-49                 [16, 149, 768]            590,592\n",
              "│    │    │    │    └─Dropout: 5-42                     [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-43                   [16, 149, 768]            1,536\n",
              "│    │    │    │    └─Wav2Vec2FeedForward: 5-44         [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-50                 [16, 149, 3072]           2,362,368\n",
              "│    │    │    │    │    └─GELUActivation: 6-51         [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Dropout: 6-52                [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Linear: 6-53                 [16, 149, 768]            2,360,064\n",
              "│    │    │    │    │    └─Dropout: 6-54                [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-45                   [16, 149, 768]            1,536\n",
              "│    │    │    └─Wav2Vec2EncoderLayer: 4-17             [16, 149, 768]            --\n",
              "│    │    │    │    └─Wav2Vec2Attention: 5-46           [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-55                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-56                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-57                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-58                 [16, 149, 768]            590,592\n",
              "│    │    │    │    └─Dropout: 5-47                     [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-48                   [16, 149, 768]            1,536\n",
              "│    │    │    │    └─Wav2Vec2FeedForward: 5-49         [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-59                 [16, 149, 3072]           2,362,368\n",
              "│    │    │    │    │    └─GELUActivation: 6-60         [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Dropout: 6-61                [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Linear: 6-62                 [16, 149, 768]            2,360,064\n",
              "│    │    │    │    │    └─Dropout: 6-63                [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-50                   [16, 149, 768]            1,536\n",
              "│    │    │    └─Wav2Vec2EncoderLayer: 4-18             [16, 149, 768]            --\n",
              "│    │    │    │    └─Wav2Vec2Attention: 5-51           [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-64                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-65                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-66                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-67                 [16, 149, 768]            590,592\n",
              "│    │    │    │    └─Dropout: 5-52                     [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-53                   [16, 149, 768]            1,536\n",
              "│    │    │    │    └─Wav2Vec2FeedForward: 5-54         [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-68                 [16, 149, 3072]           2,362,368\n",
              "│    │    │    │    │    └─GELUActivation: 6-69         [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Dropout: 6-70                [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Linear: 6-71                 [16, 149, 768]            2,360,064\n",
              "│    │    │    │    │    └─Dropout: 6-72                [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-55                   [16, 149, 768]            1,536\n",
              "│    │    │    └─Wav2Vec2EncoderLayer: 4-19             [16, 149, 768]            --\n",
              "│    │    │    │    └─Wav2Vec2Attention: 5-56           [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-73                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-74                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-75                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-76                 [16, 149, 768]            590,592\n",
              "│    │    │    │    └─Dropout: 5-57                     [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-58                   [16, 149, 768]            1,536\n",
              "│    │    │    │    └─Wav2Vec2FeedForward: 5-59         [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-77                 [16, 149, 3072]           2,362,368\n",
              "│    │    │    │    │    └─GELUActivation: 6-78         [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Dropout: 6-79                [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Linear: 6-80                 [16, 149, 768]            2,360,064\n",
              "│    │    │    │    │    └─Dropout: 6-81                [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-60                   [16, 149, 768]            1,536\n",
              "│    │    │    └─Wav2Vec2EncoderLayer: 4-20             [16, 149, 768]            --\n",
              "│    │    │    │    └─Wav2Vec2Attention: 5-61           [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-82                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-83                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-84                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-85                 [16, 149, 768]            590,592\n",
              "│    │    │    │    └─Dropout: 5-62                     [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-63                   [16, 149, 768]            1,536\n",
              "│    │    │    │    └─Wav2Vec2FeedForward: 5-64         [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-86                 [16, 149, 3072]           2,362,368\n",
              "│    │    │    │    │    └─GELUActivation: 6-87         [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Dropout: 6-88                [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Linear: 6-89                 [16, 149, 768]            2,360,064\n",
              "│    │    │    │    │    └─Dropout: 6-90                [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-65                   [16, 149, 768]            1,536\n",
              "│    │    │    └─Wav2Vec2EncoderLayer: 4-21             [16, 149, 768]            --\n",
              "│    │    │    │    └─Wav2Vec2Attention: 5-66           [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-91                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-92                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-93                 [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-94                 [16, 149, 768]            590,592\n",
              "│    │    │    │    └─Dropout: 5-67                     [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-68                   [16, 149, 768]            1,536\n",
              "│    │    │    │    └─Wav2Vec2FeedForward: 5-69         [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-95                 [16, 149, 3072]           2,362,368\n",
              "│    │    │    │    │    └─GELUActivation: 6-96         [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Dropout: 6-97                [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Linear: 6-98                 [16, 149, 768]            2,360,064\n",
              "│    │    │    │    │    └─Dropout: 6-99                [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-70                   [16, 149, 768]            1,536\n",
              "│    │    │    └─Wav2Vec2EncoderLayer: 4-22             [16, 149, 768]            --\n",
              "│    │    │    │    └─Wav2Vec2Attention: 5-71           [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-100                [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-101                [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-102                [16, 149, 768]            590,592\n",
              "│    │    │    │    │    └─Linear: 6-103                [16, 149, 768]            590,592\n",
              "│    │    │    │    └─Dropout: 5-72                     [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-73                   [16, 149, 768]            1,536\n",
              "│    │    │    │    └─Wav2Vec2FeedForward: 5-74         [16, 149, 768]            --\n",
              "│    │    │    │    │    └─Linear: 6-104                [16, 149, 3072]           2,362,368\n",
              "│    │    │    │    │    └─GELUActivation: 6-105        [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Dropout: 6-106               [16, 149, 3072]           --\n",
              "│    │    │    │    │    └─Linear: 6-107                [16, 149, 768]            2,360,064\n",
              "│    │    │    │    │    └─Dropout: 6-108               [16, 149, 768]            --\n",
              "│    │    │    │    └─LayerNorm: 5-75                   [16, 149, 768]            1,536\n",
              "├─Linear: 1-2                                           [16, 149, 256]            196,864\n",
              "├─Linear: 1-3                                           [16, 3]                   771\n",
              "=========================================================================================================\n",
              "Total params: 94,569,347\n",
              "Trainable params: 94,569,347\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 177.10\n",
              "=========================================================================================================\n",
              "Input size (MB): 3.07\n",
              "Forward/backward pass size (MB): 3869.21\n",
              "Params size (MB): 378.27\n",
              "Estimated Total Size (MB): 4250.56\n",
              "========================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Model architecture\n",
        "batch_size = 16\n",
        "summary(model6, depth=10, input_size=(batch_size, SAMPLING_RATE * SECONDS))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reference list"
      ],
      "metadata": {
        "id": "fG5nV3j8SKf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Audio Classification, Hugging Face: https://huggingface.co/docs/transformers/tasks/audio_classification"
      ],
      "metadata": {
        "id": "mV2U3c8lSxzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auto Classes, Hugging Face: https://huggingface.co/docs/transformers/v4.32.1/en/model_doc/auto#transformers.AutoModel"
      ],
      "metadata": {
        "id": "wBiV79JQS5rc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluator, Hugging Face: https://huggingface.co/docs/evaluate/package_reference/evaluator_classes"
      ],
      "metadata": {
        "id": "Cl3V9XIUSO0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model outputs: https://huggingface.co/docs/transformers/main_classes/output"
      ],
      "metadata": {
        "id": "tkYSFpHPTA7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trainer, Hugging Face: https://huggingface.co/docs/transformers/v4.32.0/en/main_classes/trainer#transformers.TrainingArguments"
      ],
      "metadata": {
        "id": "1_uJFCNpTR1f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tranformers, Hugging Face: https://huggingface.co/docs/evaluate/transformers_integrations"
      ],
      "metadata": {
        "id": "KvSAgx-DSNBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wav2Vec2, Hugging Face: https://huggingface.co/docs/transformers/model_doc/wav2vec2"
      ],
      "metadata": {
        "id": "Vb7IgxsbTFU8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wav2Vec2-Base, Hugging Face: https://huggingface.co/facebook/wav2vec2-base"
      ],
      "metadata": {
        "id": "6eVDoS5ESQlj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49e9f4310d734e87977dd306ee402d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e333a340052842a3bead93a55be7ef86",
              "IPY_MODEL_469f40035c2f4483959173b5ea70ff35",
              "IPY_MODEL_40a6d3c25c904d6e856c5dfe7001675f"
            ],
            "layout": "IPY_MODEL_38b4500df6ae4c669bfdb28463aea391"
          }
        },
        "e333a340052842a3bead93a55be7ef86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8d70dccb44b43598a2b39597ee7d759",
            "placeholder": "​",
            "style": "IPY_MODEL_87538fc591e449f9be8786354e27eff3",
            "value": "Downloading builder script: 100%"
          }
        },
        "469f40035c2f4483959173b5ea70ff35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15c848d9fb5c45cba35035968295592b",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91f3bf93def8471498e254fb5922fe5e",
            "value": 4203
          }
        },
        "40a6d3c25c904d6e856c5dfe7001675f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68705234e29a47f9a5e79eb96046552f",
            "placeholder": "​",
            "style": "IPY_MODEL_ce4d77aa788044b1ba0b9f2ab5fb5af1",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 138kB/s]"
          }
        },
        "38b4500df6ae4c669bfdb28463aea391": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8d70dccb44b43598a2b39597ee7d759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87538fc591e449f9be8786354e27eff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15c848d9fb5c45cba35035968295592b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f3bf93def8471498e254fb5922fe5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68705234e29a47f9a5e79eb96046552f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce4d77aa788044b1ba0b9f2ab5fb5af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25bb2059277a48feb1500c43b922b1ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7d5cb036ba53492bbf1eb5d4e8ddee68",
              "IPY_MODEL_e4301bfaee904e9aa1d70f02e728f0ea",
              "IPY_MODEL_91ef35ca6fad48768f3fb03de89c6389"
            ],
            "layout": "IPY_MODEL_74ca9634f7ae4d83a631cbb0a556b043"
          }
        },
        "7d5cb036ba53492bbf1eb5d4e8ddee68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15439c44f14b46968ade8a3c39b8e17a",
            "placeholder": "​",
            "style": "IPY_MODEL_c92cfe4bde354629b2b95298ed5ae4ef",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "e4301bfaee904e9aa1d70f02e728f0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb378b5048ee43beaac61cd78c6511a7",
            "max": 380267417,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b927c7d91eb4e519b4b529664fb61d4",
            "value": 380267417
          }
        },
        "91ef35ca6fad48768f3fb03de89c6389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d7fafac09224ffab2f5afb6a427bddf",
            "placeholder": "​",
            "style": "IPY_MODEL_f44ad89c4570409ba5c8f407ca74b039",
            "value": " 380M/380M [00:05&lt;00:00, 73.2MB/s]"
          }
        },
        "74ca9634f7ae4d83a631cbb0a556b043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15439c44f14b46968ade8a3c39b8e17a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c92cfe4bde354629b2b95298ed5ae4ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb378b5048ee43beaac61cd78c6511a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b927c7d91eb4e519b4b529664fb61d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d7fafac09224ffab2f5afb6a427bddf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44ad89c4570409ba5c8f407ca74b039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}